\section*{me22b048}

My favorite equation is the formula for \footnote[1]{Sunnåker M, Busetto A.G, Numminen E, Corander J, Foll M., Dessimoz C. Approximate Bayesian Computation: 2. https://doi.org/10.1371/journal.pcbi.1002803 .} \textbf{Bayes’ theorem }, which is:

\begin{equation}
        P(A|B) = \frac{P(B|A)P(A)}{P(B)}\
\end{equation}

where
\begin{itemize}
        \item P(A$|$B) denotes the posterior
        \item P(B$|$A) denotes the likelihood
        \item P(A) denotes the prior
        \item P(B) denotes the evidence 
\end{itemize}
This formula relates the conditional probability of a particular parameter value A given data B to the probability of B given A. This helps us find the probability of occurrence of an event related to any condition.One can realise the beauty of this formula when he/she uses it in machine learning, where it is extensively used.

\begin{flushleft}
Name: Vaibhav K E\\
Github User ID: vaibhavkev
\end{flushleft}
